{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = '<path_to_repo>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{current_dir}/LOL-EVE/data/benchmark_data/gnomad_indel_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_odds_ratio(low_freq_count, common_count, total_low_freq, total_common):\n",
    "    odds_low = low_freq_count / max(1, total_low_freq - low_freq_count)\n",
    "    odds_common = common_count / max(1, total_common - common_count)\n",
    "    return odds_low / odds_common\n",
    "\n",
    "def run_analysis_for_threshold(df, low_freq_range, common_threshold, columns_to_analyze, threshold_percentile):\n",
    "    n_predictions = int(len(df) * threshold_percentile)\n",
    "\n",
    "    thresholds = {}\n",
    "    for col in columns_to_analyze:\n",
    "        if col in ['PhyloP', 'CADD_raw_score']:\n",
    "            thresholds[col] = np.percentile(df[col], 100 - threshold_percentile * 100)\n",
    "            df[f'{col}_significant'] = df[col] >= thresholds[col]\n",
    "        else:\n",
    "            thresholds[col] = np.percentile(df[col], threshold_percentile * 100)\n",
    "            df[f'{col}_significant'] = df[col] <= thresholds[col]\n",
    "\n",
    "    low_freq = df[(df.MAF > low_freq_range[0]) & (df.MAF < low_freq_range[1])]\n",
    "    common = df[df.MAF >= common_threshold]\n",
    "\n",
    "    total_low_freq = len(low_freq)\n",
    "    total_common = len(common)\n",
    "\n",
    "    data = []\n",
    "    for col in columns_to_analyze:\n",
    "        low_freq_count = len(low_freq[low_freq[f'{col}_significant']])\n",
    "        common_count = len(common[common[f'{col}_significant']])\n",
    "        odds_ratio = calculate_odds_ratio(low_freq_count, common_count, total_low_freq, total_common)\n",
    "        data.append((col, odds_ratio))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_threshold_variation_plot(ax, df, low_freq_range, common_threshold, columns_to_analyze, thresholds, row, col):\n",
    "    # Color scheme remains the same\n",
    "    colors = {\n",
    "        \"LOL-EVE\": \"#00aa55\",\n",
    "        \"PhyloP\": \"#FF9AA2\",\n",
    "        \"hyenadna-tiny-1k-seqlen\": \"#A8E6CF\",\n",
    "        \"hyenadna-medium-450k-seqlen\": \"#A2D2FF\",\n",
    "        \"hyenadna-medium-160k-seqlen\": \"#FDFD96\",\n",
    "        \"hyenadna-large-1m-seqlen\": \"#FFB347\",\n",
    "        \"hyenadna-small-32k-seqlen\": \"#E0AAFF\",\n",
    "        \"caduceus-ph_seqlen-131k_d_model-256_n_layer-16\": \"#A3C1AD\",\n",
    "        \"caduceus-ps_seqlen-131k_d_model-256_n_layer-16\": \"#B19CD9\",\n",
    "        \"DNABERT-2-117M\": \"#FFD1DC\",\n",
    "        \"nucleotide-transformer-2.5b-multi-species\": \"#AFEEEE\",\n",
    "        \"nucleotide-transformer-2.5b-1000g\": \"#FFE4E1\",\n",
    "        \"nucleotide-transformer-500m-human-ref\": \"#D0F0C0\",\n",
    "        \"nucleotide-transformer-v2-500m-multi-species\": \"#F0E68C\",\n",
    "    }\n",
    "\n",
    "    for col_name in columns_to_analyze:\n",
    "        odds_ratios = []\n",
    "        for threshold in thresholds:\n",
    "            data = run_analysis_for_threshold(df, low_freq_range, common_threshold, [col_name], threshold)\n",
    "            odds_ratios.append(data[0][1])\n",
    "        \n",
    "        label = col_name.split('mean_cross_entropy_diff_')[-1] if 'mean_cross_entropy_diff_' in col_name else col_name\n",
    "        color = colors[label]\n",
    "        \n",
    "        if label in ['LOL-EVE', 'PhyloP']:\n",
    "            ax.plot(thresholds, odds_ratios, marker='o', label=label, color=color, linewidth=3, markersize=8)\n",
    "        else:\n",
    "            ax.plot(thresholds, odds_ratios, label=label, color=color, linewidth=2)\n",
    "\n",
    "    if row == 1:\n",
    "        ax.set_xlabel('Threshold (percentile)', fontsize=20)\n",
    "    else:\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    # Add y-axis label to all plots\n",
    "    ax.set_ylabel('Odds Ratio', fontsize=20)\n",
    "\n",
    "    ax.set_title(f'MAF {low_freq_range[0]}-{low_freq_range[1]} vs. â‰¥{common_threshold}', fontsize=20)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "def create_maf_threshold_panel(df, maf_thresholds, columns_to_analyze, thresholds):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 18), dpi=300)\n",
    "\n",
    "    # Find global min and max for y-axis\n",
    "    global_min = float('inf')\n",
    "    global_max = float('-inf')\n",
    "    for low_freq_range, common_threshold in maf_thresholds:\n",
    "        for col in columns_to_analyze:\n",
    "            data = [run_analysis_for_threshold(df, low_freq_range, common_threshold, [col], threshold)[0][1] for threshold in thresholds]\n",
    "            global_min = min(global_min, min(data))\n",
    "            global_max = max(global_max, max(data))\n",
    "\n",
    "    for i, ((row, col), (low_freq_range, common_threshold)) in enumerate(zip([(0,0), (0,1), (1,0), (1,1)], maf_thresholds)):\n",
    "        create_threshold_variation_plot(axs[row, col], df, low_freq_range, common_threshold, columns_to_analyze, thresholds, row, col)\n",
    "        axs[row, col].set_ylim(global_min * 0.9, global_max * 1.1)  # Set same y-axis limits for all subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "    simplified_labels = [label.replace('nucleotide-transformer', 'NT') for label in labels]\n",
    "    \n",
    "    fig.legend(handles, simplified_labels, loc='lower center', bbox_to_anchor=(0.5, -0.05),\n",
    "               ncol=2, fontsize=20, borderaxespad=0)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    plt.savefig('odds_ratio_threshold_variation_panel_improved.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function with your data and parameters\n",
    "# Define the MAF thresholds\n",
    "maf_thresholds = [\n",
    "    ((0, 0.05), 0.05),  # Original: low < 0.05, common >= 0.05\n",
    "    ((0, 0.01), 0.01),  # Very rare vs. others: low < 0.01, common >= 0.01\n",
    "    ((0.001, 0.05), 0.05),  # Low frequency vs. common: 0.001 < low < 0.05, common >= 0.05\n",
    "    ((0.001, 0.01), 0.01)  # Rare vs. others: 0.001 < low < 0.01, common >= 0.01\n",
    "]\n",
    "\n",
    "columns_to_analyze = [\n",
    "    'mean_cross_entropy_diff_hyenadna-tiny-1k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-450k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-160k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-large-1m-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-small-32k-seqlen',\n",
    "    'mean_cross_entropy_diff_caduceus-ph_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_caduceus-ps_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_DNABERT-2-117M',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-multi-species',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-1000g',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-500m-human-ref',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-v2-500m-multi-species',\n",
    "    'PhyloP',\n",
    "    'LOL-EVE'\n",
    "]\n",
    "\n",
    "# Define the thresholds to analyze (as percentiles)\n",
    "thresholds = [0.001, 0.01, 0.05]\n",
    "\n",
    "# Create the panel plot\n",
    "create_maf_threshold_panel(df, maf_thresholds, columns_to_analyze, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_threshold(scores, n_predictions):\n",
    "    \"\"\"\n",
    "    Find the threshold that gives exactly n_predictions.\n",
    "    Assumes that higher scores are more significant for both models.\n",
    "    \"\"\"\n",
    "    sorted_scores = np.sort(scores)[::-1]  # Sort in descending order\n",
    "    return sorted_scores[n_predictions - 1]\n",
    "\n",
    "def calculate_odds_ratio(low_freq_count, common_count, total_low_freq, total_common):\n",
    "    odds_low = low_freq_count / max(1, total_low_freq - low_freq_count)\n",
    "    odds_common = common_count / max(1, total_common - common_count)\n",
    "    return odds_low / odds_common\n",
    "\n",
    "def run_analysis(df, low_freq_range, common_threshold, columns_to_analyze):\n",
    "    \"\"\"\n",
    "    Run the analysis for a given MAF threshold configuration.\n",
    "    \n",
    "    :param df: The DataFrame containing the data\n",
    "    :param low_freq_range: Tuple of (min_maf, max_maf) for low-frequency variants\n",
    "    :param common_threshold: Minimum MAF for common variants\n",
    "    :param columns_to_analyze: List of columns to analyze\n",
    "    :return: Tuple of (sorted_data, total_low_freq, total_common)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Decide on the number of predictions (e.g., top 1% of variants)\n",
    "    n_predictions = int(len(df) * 0.01)\n",
    "\n",
    "    # Find thresholds and apply them\n",
    "    thresholds = {}\n",
    "    for col in columns_to_analyze:\n",
    "        if col in ['PhyloP', 'CADD_raw_score']:\n",
    "            thresholds[col] = find_threshold(df[col], n_predictions)\n",
    "            df[f'{col}_significant'] = df[col] >= thresholds[col]\n",
    "        else:\n",
    "            thresholds[col] = find_threshold(-df[col], n_predictions)\n",
    "            df[f'{col}_significant'] = df[col] <= -thresholds[col]\n",
    "\n",
    "    # Define frequency categories\n",
    "    low_freq = df[(df.MAF > low_freq_range[0]) & (df.MAF < low_freq_range[1])]\n",
    "    common = df[df.MAF >= common_threshold]\n",
    "\n",
    "    total_low_freq = len(low_freq)\n",
    "    total_common = len(common)\n",
    "\n",
    "    # Calculate odds ratios\n",
    "    data = []\n",
    "    for col in columns_to_analyze:\n",
    "        low_freq_count = len(low_freq[low_freq[f'{col}_significant']])\n",
    "        common_count = len(common[common[f'{col}_significant']])\n",
    "        odds_ratio = calculate_odds_ratio(low_freq_count, common_count, total_low_freq, total_common)\n",
    "        data.append((col, odds_ratio))\n",
    "\n",
    "    # Sort data by odds ratio\n",
    "    sorted_data = sorted(data, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_data, total_low_freq, total_common\n",
    "\n",
    "def plot_results(sorted_data, total_low_freq, total_common, low_freq_range, common_threshold):\n",
    "    \"\"\"\n",
    "    Plot the results of the analysis with specified color palette.\n",
    "    \"\"\"\n",
    "    names, odds = zip(*sorted_data)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Define colors\n",
    "    colors = {\n",
    "        \"LOL-EVE\": \"#00aa55\",  # Dartmouth green for LOLEVE\n",
    "        \"Other\": \"#2f9aea\"    # Green Blue for other bars\n",
    "    }\n",
    "\n",
    "    y_pos = np.arange(len(names))\n",
    "    bars = ax.barh(y_pos, odds, align='center', color=[colors[\"LOL-EVE\"] if name == \"LOL-EVE\" else colors[\"Other\"] for name in names])\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([name.split('mean_cross_entropy_diff_')[-1] for name in names] , fontsize=16)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Odds ratio',fontsize=16)\n",
    "    ax.set_ylabel('Model',fontsize=16)\n",
    "    ax.yaxis.labelpad = 20 \n",
    "    #ax.set_title(f'gnomAD v4 low-frequency ({low_freq_range[0]}-{low_freq_range[1]}) vs. common (>={common_threshold})\\nn={total_low_freq} vs. {total_common}')\n",
    "\n",
    "    min_x = 1.05  # Minimum x-coordinate for text\n",
    "    offset = 0.05  # Offset from the end of the bar\n",
    "\n",
    "    for i, v in enumerate(odds):\n",
    "        x_pos = max(v + offset, min_x)\n",
    "        ax.text(x_pos, i, f'{v:.2f}', va='center', ha='left', fontsize=16)\n",
    "\n",
    "    ax.set_xlim(1, max(odds) * 1.1)\n",
    "    ax.axvline(x=1, color='r', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Add legend\n",
    "    # legend_elements = [plt.Rectangle((0,0),1,1, facecolor=colors[\"LOL-EVE\"], label='LOL-EVE'),\n",
    "    #                    plt.Rectangle((0,0),1,1, facecolor=colors[\"Other\"], label='Other models')]\n",
    "    # ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "df.rename({'mean_cross_entropy_diff_hyenadna-medium-450k-seqlen': 'HyenaDNA',\n",
    "           'mean_cross_entropy_diff_caduceus-ps_seqlen-131k_d_model-256_n_layer-16' : 'Caduceus',\n",
    "           'mean_cross_entropy_diff_nucleotide-transformer-500m-human-ref': 'NT',\n",
    "           'PhyloP':'PhyloP',\n",
    "           'mean_cross_entropy_diff_DNABERT-2-117M': 'DNABERT-2'\n",
    "           }, inplace=True, axis=1)\n",
    "\n",
    "columns_to_analyze = [\n",
    "    'HyenaDNA',\n",
    "    'Caduceus',\n",
    "    'NT',\n",
    "    'DNABERT-2',\n",
    "    'PhyloP',\n",
    "    'LOL-EVE'\n",
    "]\n",
    "\n",
    "\n",
    "# Define different MAF thresholds to analyze\n",
    "maf_thresholds = [\n",
    "  #  ((0, 0.05), 0.05),  # Original: low < 0.05, common >= 0.05\n",
    "    ((0, 0.05), 0.05),  # Very rare vs. others: low < 0.01, common >= 0.01\n",
    "  #  ((0.001, 0.05), 0.05),  # Low frequency vs. common: 0.01 < low < 0.05, common >= 0.05\n",
    "  #  ((0.001, 0.01), 0.01)  # Rare vs. others: 0.001 < low < 0.01, common >= 0.01\n",
    "]\n",
    "\n",
    "# Run analysis for each threshold configuration\n",
    "for low_freq_range, common_threshold in maf_thresholds:\n",
    "    print(f\"\\nAnalyzing MAF thresholds: Low frequency {low_freq_range}, Common >= {common_threshold}\")\n",
    "    sorted_data, total_low_freq, total_common = run_analysis(df, low_freq_range, common_threshold, columns_to_analyze)\n",
    "    plot_results(sorted_data, total_low_freq, total_common, low_freq_range, common_threshold)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_expression_genes = [str(g).lower() for g in list(pd.read_csv('gtex_consistent_genes_500.txt')['Gene Symbol'].dropna())]\n",
    "variable_expression_genes = [str(g).lower() for g in list(pd.read_csv('gtex_variable_genes_500.txt')['Gene Symbol'].dropna())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{current_dir}/LOL-EVE/data/benchmark_data/tfbs_disruptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from scipy.stats import pointbiserialr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import random\n",
    "\n",
    "# 1. Function to compare transcription factors across groups and calculate statistics\n",
    "def compare_tf_across_groups(df, group1_genes, group2_genes, score_columns):\n",
    "    \"\"\"\n",
    "    Compare each TF's scores between two groups of genes for all score columns, including paired t-test, \n",
    "    point-biserial correlation, and additional statistics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for tf in df['TF'].unique():\n",
    "\n",
    "        for score_col in score_columns:\n",
    "\n",
    "            # Get scores for each group\n",
    "            group1_scores = df[(df.GENE.isin(group1_genes)) & (df.TF == tf)][score_col]\n",
    "            group2_scores = df[(df.GENE.isin(group2_genes)) & (df.TF == tf)][score_col]\n",
    "            \n",
    "            if len(group1_scores) > 0 and len(group2_scores) > 0:\n",
    "                # Create binary group labels (0 for Group 1, 1 for Group 2)\n",
    "                all_scores = np.concatenate([group1_scores, group2_scores])\n",
    "                group_labels = np.array([0] * len(group1_scores) + [1] * len(group2_scores))\n",
    "\n",
    "                # Point-biserial correlation\n",
    "                biserial_corr, _ = pointbiserialr(group_labels, all_scores)\n",
    "\n",
    "                # Perform paired t-test if group sizes match, otherwise use Mann-Whitney U test\n",
    "                if len(group1_scores) == len(group2_scores):\n",
    "                    statistic, p_value = stats.ttest_rel(group1_scores, group2_scores)\n",
    "                else:\n",
    "                    statistic, p_value = stats.mannwhitneyu(group1_scores, group2_scores, alternative='two-sided')\n",
    "\n",
    "                # Append results with additional metrics\n",
    "                results.append({\n",
    "                    'TF': tf,\n",
    "                    'score_column': score_col,\n",
    "                    'statistic': statistic,\n",
    "                    'p_value': p_value,\n",
    "                    'biserial_corr': biserial_corr,\n",
    "                    'group1_mean': np.mean(group1_scores),\n",
    "                    'group2_mean': np.mean(group2_scores),\n",
    "                    'group1_median': np.median(group1_scores),\n",
    "                    'group2_median': np.median(group2_scores),\n",
    "                })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Perform FDR correction\n",
    "    _, q_values = fdrcorrection(results_df['p_value'])\n",
    "    results_df['q_value'] = q_values\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# 2. Function to plot the biological expectation accuracy\n",
    "def plot_biological_expectation_accuracy(results_df, file_name, group1_name, group2_name):\n",
    "    percentages = []\n",
    "    fontsize = 16  # Slightly reduced from 20 to fit better\n",
    "    \n",
    "    for score_col in results_df['score_column'].unique():\n",
    "        score_results = results_df[results_df['score_column'] == score_col]\n",
    "        valid_results = score_results[score_results['group2_mean'] > score_results['group1_mean']]\n",
    "        percentage = (len(valid_results) / len(score_results)) * 100 if len(score_results) > 0 else 0\n",
    "        \n",
    "        percentages.append({\n",
    "            'score_column': score_col.split('mean_cross_entropy_diff_')[-1], \n",
    "            'percentage': percentage\n",
    "        })\n",
    "\n",
    "    percentage_df = pd.DataFrame(percentages)\n",
    "    \n",
    "    # Calculate delta accuracy and sort\n",
    "    percentage_df['delta_accuracy'] = percentage_df['percentage'] - 50\n",
    "    percentage_df = percentage_df.sort_values('delta_accuracy', ascending=False)\n",
    "    \n",
    "    # Adjust figure size\n",
    "    num_models = len(percentage_df)\n",
    "    fig_width = max(12, num_models * 0.8)  # Minimum width of 12, scales with number of models\n",
    "    plt.figure(figsize=(fig_width, 10))\n",
    "    \n",
    "    colors = {\n",
    "        \"LOL-EVE\": \"#00aa55\",\n",
    "        \"Other\": \"#2f9aea\"\n",
    "    }\n",
    "    \n",
    "    bar_colors = [colors[\"LOL-EVE\"] if col == \"LOL-EVE\" else colors[\"Other\"] for col in percentage_df['score_column']]\n",
    "    \n",
    "    ax = sns.barplot(data=percentage_df, x='score_column', y='delta_accuracy', palette=bar_colors)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=fontsize, labelpad=20)\n",
    "    plt.ylabel('Delta Accuracy (%)', fontsize=fontsize, labelpad=20)\n",
    "    \n",
    "    for i, v in enumerate(percentage_df['delta_accuracy']):\n",
    "        label = f'{v:.1f}%'\n",
    "        plt.text(i, v + 0.5, label, ha='center', va='bottom', fontsize=fontsize-4, rotation=0)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right', fontsize=fontsize-2)\n",
    "    plt.yticks(fontsize=fontsize-2)\n",
    "    \n",
    "    # Adjust y-axis limits for better bar visibility\n",
    "    y_min, y_max = plt.ylim()\n",
    "    plt.ylim(y_min, y_max + 5)\n",
    "    \n",
    "    # Adjust layout and save with higher DPI\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "score_columns = [\n",
    "    'mean_cross_entropy_diff_hyenadna-tiny-1k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-450k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-160k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-large-1m-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-small-32k-seqlen', \n",
    "    'LOL-EVE',\n",
    "    'mean_cross_entropy_diff_DNABERT-2-117M',\n",
    "    'mean_cross_entropy_diff_caduceus-ph_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_caduceus-ps_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-multi-species',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-1000g',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-500m-human-ref',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-v2-500m-multi-species',\n",
    "    'Phylop'\n",
    "]\n",
    "\n",
    "\n",
    "# # Group comparison (example)\n",
    "group1 = consistent_expression_genes\n",
    "group2 = variable_expression_genes\n",
    "\n",
    "results = compare_tf_across_groups(df, group1, group2, score_columns)\n",
    "\n",
    "results['score_column'] = results['score_column'].apply(lambda x:'PhyloP' if x == 'Phylop' else x)\n",
    "\n",
    "plot_biological_expectation_accuracy(results, 'biological_expectation_accuracy_full.png', 'Consistent_Expression', 'Variable_Expression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_info(model_name):\n",
    "    if 'hyenadna' in model_name.lower():\n",
    "        return 'hyenadna', 'HyenaDNA'\n",
    "    elif 'caduceus' in model_name.lower():\n",
    "        return 'caduceus', 'Caduceus'\n",
    "    elif 'nucleotide-transformer' in model_name.lower():\n",
    "        return 'nucleotide-transformer', 'NT'\n",
    "    elif 'dnabert' in model_name.lower():\n",
    "        return 'dnabert', 'DNABERT-2'\n",
    "    else:\n",
    "        return model_name, model_name  # For unique models like LOL-EVE, PhyloP\n",
    "\n",
    "def plot_biological_expectation_accuracy(results_df, file_name, group1_name, group2_name):\n",
    "    percentages = []\n",
    "    for score_col in results_df['score_column'].unique():\n",
    "        score_results = results_df[results_df['score_column'] == score_col]\n",
    "        valid_results = score_results[score_results['group2_mean'] > score_results['group1_mean']]\n",
    "        percentage = (len(valid_results) / len(score_results)) * 100 if len(score_results) > 0 else 0\n",
    "        percentages.append({'score_column': score_col, 'percentage': percentage})\n",
    "    \n",
    "    percentage_df = pd.DataFrame(percentages)\n",
    "    \n",
    "    # Get the best model for each family\n",
    "    best_models = {}\n",
    "    for model in percentage_df['score_column']:\n",
    "        family, simplified_name = get_model_info(model)\n",
    "        if family not in best_models or percentage_df[percentage_df['score_column'] == model]['percentage'].values[0] > best_models[family][1]:\n",
    "            best_models[family] = (model, percentage_df[percentage_df['score_column'] == model]['percentage'].values[0], simplified_name)\n",
    "\n",
    "    # Filter and prepare the final DataFrame for plotting\n",
    "    best_models_df = pd.DataFrame([\n",
    "        {'score_column': simplified_name, 'percentage': percentage, 'full_name': model}\n",
    "        for family, (model, percentage, simplified_name) in best_models.items()\n",
    "    ]).sort_values('percentage', ascending=False)\n",
    "\n",
    "    # Calculate delta accuracy\n",
    "    best_models_df['delta_accuracy'] = best_models_df['percentage'] - 50\n",
    "\n",
    "    # Adjust figure size based on the number of columns\n",
    "    num_cols = len(best_models_df)\n",
    "    fig_width = max(14, num_cols * 1.5)  # Increased minimum width and scaling factor\n",
    "    plt.figure(figsize=(fig_width, 10))  # Increased height to accommodate larger fonts\n",
    "    \n",
    "    colors = {\n",
    "        \"LOL-EVE\": \"#00aa55\",\n",
    "        \"Other\": \"#2f9aea\"\n",
    "    }\n",
    "    \n",
    "    bar_colors = [colors[\"LOL-EVE\"] if col == \"LOL-EVE\" else colors[\"Other\"] for col in best_models_df['score_column']]\n",
    "    \n",
    "    ax = sns.barplot(data=best_models_df, x='score_column', y='delta_accuracy', palette=bar_colors)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    \n",
    "    plt.ylabel('Delta Accuracy (%)', fontsize=20, labelpad=20)  # Increased font size\n",
    "    plt.xlabel('Model', fontsize=20, labelpad=20)  # Increased font size\n",
    "    \n",
    "    for i, v in enumerate(best_models_df['delta_accuracy']):\n",
    "        label = f'{v:.1f}%'\n",
    "        plt.text(i, v + 0.5, label, ha='center', va='bottom', fontsize=16, rotation=0)  # Increased font size\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right', fontsize=16)  # Increased font size\n",
    "    plt.yticks(fontsize=16)  # Increased font size\n",
    "    \n",
    "    # Adjust y-axis limits for better bar visibility\n",
    "    y_min, y_max = plt.ylim()\n",
    "    plt.ylim(y_min, y_max + 7)  # Increased upper limit to accommodate larger labels\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print selected models\n",
    "    print(\"Selected models:\")\n",
    "    for _, row in best_models_df.iterrows():\n",
    "        print(f\"{row['score_column']}: {row['full_name']}\")\n",
    "\n",
    "\n",
    "plot_biological_expectation_accuracy(results, 'best_models_comparison.png', 'Consistent_Expression', 'Variable_Expression')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

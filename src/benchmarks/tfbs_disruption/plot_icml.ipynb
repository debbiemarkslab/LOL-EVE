{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import variation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from scipy.stats import pointbiserialr\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = [\n",
    "    'mean_cross_entropy_diff_hyenadna-tiny-1k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-450k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-medium-160k-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-large-1m-seqlen',\n",
    "    'mean_cross_entropy_diff_hyenadna-small-32k-seqlen', \n",
    "    'mean_cross_entropy_diff_DNABERT-2-117M',\n",
    "    'mean_cross_entropy_diff_caduceus-ph_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_caduceus-ps_seqlen-131k_d_model-256_n_layer-16',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-multi-species',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-2.5b-1000g',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-500m-human-ref',\n",
    "    'mean_cross_entropy_diff_nucleotide-transformer-v2-500m-multi-species',\n",
    "    'Phylop','GPN',\n",
    "    'GC_percentage_delta',\n",
    "    'Distance_TSS',\n",
    "    'LOL-EVE', 'Enformer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_biomart_data(file_path):\n",
    "    \"\"\"Load Biomart data for gene name conversion.\"\"\"\n",
    "    biomart_df = pd.read_csv(file_path, sep='\\t', usecols=['Gene stable ID', 'Gene name'])\n",
    "    return dict(zip(biomart_df['Gene stable ID'], biomart_df['Gene name']))\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def load_gtex_expression_data(file_path):\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        next(f)  # Skip headers\n",
    "        next(f)\n",
    "        df = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "    return df.drop('Description', axis=1) if 'Description' in df.columns else df\n",
    "\n",
    "def map_gene_names(cv_df, gene_map):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    result_df = cv_df.copy()\n",
    "    \n",
    "    # Create a mapping function that handles missing keys\n",
    "    def get_gene_name(ensembl_id):\n",
    "        # Extract the base ENSEMBL ID (before the dot)\n",
    "        base_id = ensembl_id.split('.')[0]\n",
    "        return gene_map.get(base_id, ensembl_id)  # Return original ID if not found\n",
    "    \n",
    "    # Create a new index with mapped gene names\n",
    "    result_df.index = result_df.index.map(get_gene_name)\n",
    "    \n",
    "    # Sort by values for better visualization\n",
    "    result_df = result_df.sort_values(ascending=False)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def series_to_df(series, value_column_name='Value'):\n",
    "    # Convert series to DataFrame\n",
    "    df = series.to_frame(name=value_column_name)\n",
    "    \n",
    "    # Reset index to make gene names a column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Rename the index column to 'Gene'\n",
    "    df = df.rename(columns={'index': 'Gene'})\n",
    "    \n",
    "    # Sort by value in descending order (optional)\n",
    "    df = df.sort_values(by=value_column_name, ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_expression_variability(expression_data):\n",
    "    # Vectorized calculation of coefficient of variation\n",
    "    mean = expression_data.mean(axis=1)\n",
    "    std = expression_data.std(axis=1)\n",
    "    cv = std / mean\n",
    "    return cv.sort_values()\n",
    "\n",
    "\n",
    "def compare_tf_across_groups_vectorized(df, group1_genes, group2_genes, score_columns):\n",
    "    # Pre-compute gene group masks\n",
    "    group1_mask = df.GENE.isin(group1_genes)\n",
    "    group2_mask = df.GENE.isin(group2_genes)\n",
    "    \n",
    "    results = []\n",
    "    unique_tfs = df['TF'].unique()\n",
    "    \n",
    "    # Create random scores for comparison\n",
    "    score_columns = list(score_columns) \n",
    "    \n",
    "    for tf in unique_tfs:\n",
    "        tf_mask = df.TF == tf\n",
    "        \n",
    "        # Get scores for both groups at once\n",
    "        group1_data = df[group1_mask & tf_mask][score_columns]\n",
    "        group2_data = df[group2_mask & tf_mask][score_columns]\n",
    "        \n",
    "        if len(group1_data) == 0 or len(group2_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        for score_col in score_columns:\n",
    "            group1_scores = group1_data[score_col].values\n",
    "            group2_scores = group2_data[score_col].values\n",
    "            \n",
    "            # Compute statistics\n",
    "            all_scores = np.concatenate([group1_scores, group2_scores])\n",
    "            group_labels = np.concatenate([np.zeros(len(group1_scores)), np.ones(len(group2_scores))])\n",
    "            \n",
    "            biserial_corr, _ = pointbiserialr(group_labels, all_scores)\n",
    "            \n",
    "            if len(group1_scores) == len(group2_scores):\n",
    "                statistic, p_value = stats.ttest_rel(group1_scores, group2_scores)\n",
    "            else:\n",
    "                statistic, p_value = stats.mannwhitneyu(group1_scores, group2_scores, alternative='two-sided')\n",
    "            \n",
    "            results.append({\n",
    "                'TF': tf,\n",
    "                'score_column': score_col,\n",
    "                'statistic': statistic,\n",
    "                'p_value': p_value,\n",
    "                'biserial_corr': biserial_corr,\n",
    "                'group1_mean': np.mean(group1_scores),\n",
    "                'group2_mean': np.mean(group2_scores),\n",
    "                'group1_median': np.median(group1_scores),\n",
    "                'group2_median': np.median(group2_scores),\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    if len(results_df) > 0:\n",
    "        _, q_values = fdrcorrection(results_df['p_value'])\n",
    "        results_df['q_value'] = q_values\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_vs_percentile(cv, results, score_columns, training_genes, percentiles=[1]):\n",
    "    print(f\"Starting analysis with {len(cv)} genes and {len(results)} results rows\")\n",
    "    print(f\"Will analyze percentiles: {percentiles}\")\n",
    "    \n",
    "    # Color mapping\n",
    "    colors = {\n",
    "        \"LOL-EVE\": \"#00aa55\",\n",
    "        \"Phylop\": \"#FAD4D4\",\n",
    "        \"mean_cross_entropy_diff_hyenadna-tiny-1k-seqlen\": \"#B7E4C7\",\n",
    "        \"mean_cross_entropy_diff_hyenadna-medium-450k-seqlen\": \"#A9D6E5\",\n",
    "        \"mean_cross_entropy_diff_hyenadna-medium-160k-seqlen\": \"#FFF3B0\",\n",
    "        \"mean_cross_entropy_diff_hyenadna-large-1m-seqlen\": \"#FBC4AB\",\n",
    "        \"mean_cross_entropy_diff_hyenadna-small-32k-seqlen\": \"#D7BBF5\",\n",
    "        \"mean_cross_entropy_diff_caduceus-ph_seqlen-131k_d_model-256_n_layer-16\": \"#C1D3B4\",\n",
    "        \"mean_cross_entropy_diff_caduceus-ps_seqlen-131k_d_model-256_n_layer-16\": \"#CFB7E4\",\n",
    "        \"mean_cross_entropy_diff_DNABERT-2-117M\": \"#FFC9C9\",\n",
    "        \"mean_cross_entropy_diff_nucleotide-transformer-2.5b-multi-species\": \"#B5C9E5\",\n",
    "        \"mean_cross_entropy_diff_nucleotide-transformer-2.5b-1000g\": \"#FFE5B4\",\n",
    "        \"mean_cross_entropy_diff_nucleotide-transformer-500m-human-ref\": \"#C6E5B0\",\n",
    "        \"mean_cross_entropy_diff_nucleotide-transformer-v2-500m-multi-species\": \"#BEE0E5\",\n",
    "        \"Enformer\": \"#F7CAB9\",\n",
    "        \"Distance_TSS\": \"#C4D6E7\",\n",
    "        \"GC_percentage_delta\": \"#E6CCF5\",\n",
    "        \"GPN\": \"#B6E2D3\"\n",
    "    }\n",
    "    \n",
    "    # Initialize lists to store data for each score column\n",
    "    plot_data = []\n",
    "    \n",
    "    # Pre-compute percentile cutoffs\n",
    "    cv_values = cv['Expression'].values\n",
    "    percentile_cutoffs = {\n",
    "        p: (np.percentile(cv_values, p), np.percentile(cv_values, 100-p))\n",
    "        for p in percentiles\n",
    "    }\n",
    "    \n",
    "    for p in percentiles:\n",
    "        print(f\"\\nProcessing percentile {p}...\")\n",
    "        bottom_cutoff, top_cutoff = percentile_cutoffs[p]\n",
    "        \n",
    "        # Vectorized gene selection\n",
    "        top_genes = set(cv[cv['Expression'] >= top_cutoff]['Gene'])\n",
    "        bottom_genes = set(cv[cv['Expression'] <= bottom_cutoff]['Gene'])\n",
    "        print(f\"Selected {len(top_genes)} top genes and {len(bottom_genes)} bottom genes\")\n",
    "        results_comp = compare_tf_across_groups_vectorized(results, bottom_genes, top_genes, score_columns)\n",
    "        \n",
    "        if len(results_comp) > 0:\n",
    "            # Calculate accuracy for each score column separately\n",
    "            for score_col in score_columns:\n",
    "                score_results = results_comp[results_comp['score_column'] == score_col]\n",
    "                if len(score_results) > 0:\n",
    "                    accuracy = (np.sum(score_results['group2_mean'] > score_results['group1_mean']) \n",
    "                              / len(score_results) * 100)\n",
    "                    plot_data.append({\n",
    "                        'percentile': p,\n",
    "                        'accuracy': accuracy - 50,\n",
    "                        'score': score_col\n",
    "                    })\n",
    "    \n",
    "    # Create visualization\n",
    "    print(\"\\nCreating final visualization...\")\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    data = pd.DataFrame(plot_data)\n",
    "    print(f\"Final data points: {len(data)}\")\n",
    "    \n",
    "    # Create line plot with different line for each score using custom colors\n",
    "    for score in data['score'].unique():\n",
    "        score_data = data[data['score'] == score]\n",
    "        color = colors.get(score, '#000000')  # Default to black if color not found\n",
    "        sns.lineplot(\n",
    "            data=score_data,\n",
    "            x='percentile',\n",
    "            y='accuracy',\n",
    "            label=score,\n",
    "            color=color,\n",
    "            marker='o',\n",
    "            ax=ax\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Percentile Threshold (%)')\n",
    "    ax.set_ylabel('Biological Accuracy (%)')\n",
    "    ax.set_title('Biological Accuracy vs Percentile Threshold by Score')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    # Rotate legend labels for better readability\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "# Main execution\n",
    "\n",
    "# File paths\n",
    "gtex_file = \"/n/groups/marks/users/courtney/projects/regulatory_genomics/models/promEV_private/benchmarks/tfbs_removal/data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz\"\n",
    "biomart_file_path = \"/n/groups/marks/users/courtney/projects/regulatory_genomics/datasets/BIOMART/mart_export_9_20.txt\"\n",
    "gene_map = load_biomart_data(biomart_file_path)\n",
    "\n",
    "# Load data efficiently\n",
    "training_genes_df = pd.read_table('/n/groups/marks/databases/whole_genome_alignments/raw_sequences/447_full/promoters_1000_v2/Homo_sapiens_promoters_1000_raw_no_overlap_filtered.bed', header=None)\n",
    "training_genes_df[3] = training_genes_df[3].apply(lambda x: x.split('promoter_')[1])\n",
    "training_genes = training_genes_df[3].unique()\n",
    "\n",
    "# Load GTEx data and calculate CV\n",
    "expression_data = load_gtex_expression_data(gtex_file)\n",
    "cv = calculate_expression_variability(expression_data)\n",
    "cv.dropna(inplace=True)\n",
    "\n",
    "mapped_df = map_gene_names(cv, gene_map)\n",
    "cv = series_to_df(mapped_df, value_column_name='Expression')\n",
    "cv.rename({'Name':'Gene'}, axis=1, inplace=True)\n",
    "\n",
    "cv = cv[cv.Gene.isin(training_genes)]\n",
    "cv.Gene = cv.Gene.apply(lambda x: x.lower())\n",
    "# Load results more efficiently\n",
    "results = df\n",
    "\n",
    "# # Create and save plot\n",
    "fig = plot_accuracy_vs_percentile(cv, results, score_columns, training_genes)\n",
    "plt.savefig('accuracy_vs_percentile_with_training.svg', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight',\n",
    "            format='svg',\n",
    "            transparent=True,\n",
    "            facecolor='none',\n",
    "            edgecolor='none')\n",
    "\n",
    "# plt.savefig('accuracy_vs_percentile_with_training2.png', \n",
    "#             dpi=300, \n",
    "#             bbox_inches='tight')\n",
    "plt.close(fig)  # Clean up memory"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
